<!DOCTYPE html>
<html lang="en">

<head>
    <title>Assignment 3: Dynamic Memory Management</title>

    <div class="common-head">
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <base href="/elec50014/">
        <!-- Style sheets -->
        <link rel="stylesheet" href="css/prism.css">
        <link rel="stylesheet" href="css/style.css">

        <!-- Scripts -->
        <script src="js/prism.js"></script>
        <script src="js/loadCodeAndThemes.js"></script>
        <script src="js/insertCode.js"></script>
        <script src="js/insertPC.js"></script>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </div>

     <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-03CDK5R9LR"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-03CDK5R9LR');
    </script>
</head>


<body>
    <div class="toc">
        <section class="toc-content">
            <h5>Table of Contents</h5>
            <a href="Docs/Assignment3.html#intro">Introduction</a>
            <a href="Docs/Assignment3.html#p1">1. Conceptual Overview</a>
            <div style="margin-left:20px;">
                <a href="Docs/Assignment3.html#p1.1"><code><strong>smalloc</strong></code> and <code><strong>sfree</strong></code></a>
                <a href="Docs/Assignment3.html#p1.2">Memory organization</a>
                <a href="Docs/Assignment3.html#p1.3">Allocation/deallocation</a>
                <a href="Docs/Assignment3.html#p1.4">Implementing <code><strong>freelist</strong></code></a>
                <a href="Docs/Assignment3.html#p1.5"><code><strong>freelist</strong></code> storage</a>
                <a href="Docs/Assignment3.html#p1.6">Initializing memory</a>
                <a href="Docs/Assignment3.html#p1.7">The algorithms</a>
            </div>
            <a href="Docs/Assignment3.html#p2">2. Implement and Test Version 1</a>
            <a href="Docs/Assignment3.html#p3">3. Implement and Test Version 2</a>
            <a href="Docs/Assignment3.html#p4">4. Stress-test Version 2</a>
            <a href="Docs/Assignment3.html#p5">5. PE: Size-class Arenas</a>
            <a href="Docs/Assignment3.html#p6">6. Further Enhancements</a>
        </section>
    </div>


    <h1 class="align-with-statement"> Assignment 3: Dynamic Memory Management</h1>
    <section class="statement">
        <div id="intro">
            <h2>Introduction</h2>
            <p>This assignment focuses on a fundamental aspect of any memory management system, namely the issue of
                <strong>free-space management</strong>. The goal is to implement our own versions of malloc and free
                (<strong>smalloc</strong> and <strong>sfree</strong>) to manage memory on a process’s heap.
            </p>

            <p>This exercise is relevant because not only does it give us more insight into memory allocation strategies
                that are a fundamental feature of any programming language, but also because free-space management is a
                problem that the operating system itself has to
                solve when, for example, managing portions of the address space of a process or allocating free space to
                files on disk in a file system.</p>

            <p><strong>Important note:</strong> This assignment is both conceptually rich and programmatically
                rewarding. We will
                introduce key concepts required to implement a dynamic memory manager, including the idea of a
                <strong>free list</strong>, the techniques of <strong>splitting</strong>
                and <strong>merging</strong> (or coalescing) adjacent free blocks, and strategies for selecting free
                space (e.g., <strong>first-fit</strong>, <strong>next-fit</strong>,
                <strong>best-fit</strong>, etc). Therefore this assignment requires a little more reading than the
                previous ones.
                Additionally, some starter code will be provided to set you on the path to implementing these
                ideas. Overall, some sections emphasize the concepts while others, especially
                the later ones, focus more on coding.
            </p>
            <p>Let's begin!</p>
        </div>

        <div id="p1">
            <h3><small>1. </small>Conceptual Overview</h3>
            <p>In this section, I broadly lay out various concepts and strategies we will need to implement to complete
                this assignment.</p>

            <h4 id="p1.1"><code><strong>smalloc</strong></code> and <code><strong>sfree</strong></code></h4>

            <p>First, to clarify our requirements, consider the prototypes of the two functions we need to implement,
                namely <code><strong>smalloc</strong></code> and <code><strong>sfree</strong></code>. Their design
                mimics exactly that of the C <code><strong>malloc</strong></code> and <code><strong>free</strong></code>
                functions.</p>

            <p><code><strong>smalloc:</strong></code></p>
            <div class="code-container" data-filename="inline">
                <pre class="language-c"><code>void *smalloc(size_t num_bytes);</code></pre>
            </div>

            <p><code><strong>sfree:</strong></code></p>
            <div class="code-container" data-filename="inline">
                <pre class="language-c"><code>void sfree(void *mem_ptr);</code></pre>
            </div>

            <p>The function <code><strong>smalloc</strong></code> returns a <code><strong>void*</strong></code>, which
                is a generic
                pointer to a block of memory on the heap that can be cast to any data type. Its parameter specifies the
                number of bytes to allocate.</p>

            <p>The function <code><strong>sfree</strong></code> returns <code><strong>void</strong></code>, meaning it
                does not return a
                value, and its parameter is a pointer to a block of memory previously allocated with
                <code><strong>smalloc</strong></code>, indicating which block should be released back to the pool of
                free space.
            </p>

            <h4 id="p1.2">Memory organization</h4>

            <p>First, we will use the <code><strong>mmap</strong></code> system call to obtain a large block of heap
                memory from the operating system.</p>

            <p>Each call to the <code><strong>smalloc</strong></code> function will then allocate to the caller a
                smaller piece—whose size depends on the value of <code><strong>num_bytes</strong></code>—as a sub-block
                from this larger block of heap memory.</p>

            <p>To manage this process properly, we need a way to keep track of which parts of the memory are free
                and available for allocation. Because of <code><strong>sfree</strong></code> and the fact that
                allocations
                and deallocations may occur in any order, the free memory will usually not be a single contiguous block,
                but rather several non-contiguous sub-blocks, of different sizes, scattered within the larger block.</p>

            <p>In short: at the very beginning, the entire memory block is free. Then as allocations and deallocations
                take place,
                this block gradually becomes divided into smaller allocated and free sub-blocks.</p>

            <p>To keep track of the free sub-blocks that can be reused in later allocations, we will use a special data
                structure called a <code><strong>freelist</strong></code>, which is simply a linked list of the free
                sub-blocks of memory.</p>

            <p>Before going into the implementation details of the <code><strong>freelist</strong></code>, it will be
                helpful to look at a few examples to understand its purpose clearly.</p>

            <h4 id="p1.3">Allocation and deallocation examples</h4>
            <p>As a simple example, consider a tiny memory block of 30 bytes (in the assignment we will be working with
                several MBs).</p>
            <p>Now consider the following sequence of <code><strong>smalloc</strong></code> calls:</p>
            <div class="code-container" data-filename="inline">
                <pre class="language-c"><code>void *ptr1 =  smalloc(10);
void *ptr2 =  smalloc(10);
void *ptr3 =  smalloc(10);
</code></pre>
            </div>
            <p>This is followed by a single <code><strong>sfree</strong></code> call, as follows:</p>
            <div class="code-container" data-filename="inline"></div>
            <pre class="language-c"><code>sfree(ptr1);</code></pre>
        </div>

        <p>Figure 1 depicts the situations before and after the <code><strong>sfree</strong></code> call.</p>

        <figure style="text-align: center;">
            <img src="img/fragmentation1.png" alt="fragmentation-example" style="max-width: 50%; height: auto;">
            <figcaption>Figure 1: The state of the memory block after three <code><strong>smalloc</strong></code>
                and one <code><strong>sfree</strong></code> call.</figcaption>
        </figure>

        <p>At this point, the <code><strong>freelist</strong></code> contains only one entry: for the block of size 10
            bytes starting at
            address 0.</p>

        <p>Now let's consider another call to <code><strong>sfree</strong></code>.</p>

        <div class="code-container" data-filename="inline"></div>
        <pre class="language-c"><code>sfree(ptr3);</code></pre>
        </div>

        <p>The resultant state of the memory is shown in Figure 2.</p>

        <figure style="text-align: center;">
            <img src="img/fragmentation2.png" alt="fragmentation-example" style="max-width: 50%; height: auto;">
            <figcaption>Figure 2: The state of the memory block after a second <code><strong>sfree</strong></code> call.
            </figcaption>
        </figure>

        <p>Now the <code><strong>freelist</strong></code> contains two entries: one for the block of size 10 bytes
            starting at address 0, and another for the block of size 10 bytes starting at address 20. If the user
            requests another block of memory of size 10 bytes or less, the allocation can be satisfied from one of these
            free blocks.</p>

        <p>However, if the user requests, for example, 15 bytes, the request will fail because there is no single
            contiguous block of memory of size 15 bytes or more, even though the total amount of free memory is 20
            bytes.</p>

        <p>This is the classic problem of <strong>external fragmentation</strong>, which refers to unused memory space
            that exists between allocated blocks. One of the main goals of a good allocation strategy is to reduce
            external fragmentation as much as possible.</p>

        <p>At this point, you may be asking yourself another question: do we keep track of the allocated blocks? The
            answer is yes and no.</p>

        <p>We keep some metadata with each allocated block (as will be shown below). However, the responsibility of
            keeping track of the allocated memory lies with the programmer.
            The programmer must maintain pointers to the allocated blocks and use
            these to deallocate these blocks when they are no longer required, by calling the
            <code><strong>sfree</strong></code> function. If the programmer is not careful and loses track of
            these pointers, the memory will never be freed and is effectively lost, or in other words,
            <strong>leaked</strong>.
        </p>

        <p>However, once the programmer makes a valid deallocation, the <code><strong>sfree</strong></code> function
            must return the block to the <code><strong>freelist</strong></code> appropriately.</p>

        <h4 id="p1.4">Implementing <code><strong>freelist</strong></code></h4>
        <p>Two important questions to answer regarding the <code><strong>freelist</strong></code> are these: where is it
            stored, and what information does each node of the list contain? We will answer the second question first.
        </p>

        <p>Each node of the <code><strong>freelist</strong></code> must contain two pieces of information: (1) the size
            (in bytes) of the free block represented by this node, and (2) a pointer to the next node in the list (which
            may be <code><strong>NULL</strong></code> if this is the last node).</p>

        <p>More concretely, in our implementation a <code><strong>freelist</strong></code> node is defined as follows:
        </p>

        <div class="code-container" data-filename="inline"></div>
        <pre class="language-c"><code>typedef struct __common_header_t {
    int size;                     // size of the memory block
    struct common_header *next;   // pointer to the next node of the freelist 
} common_header_t;</code></pre>

        <p>The name <code><strong>common_header_t</strong></code> suggests that this header (or node) is common to
            both the <code><strong>freelist</strong></code> as well as the allocated blocks in the memory. This idea
            will
            become clear as we answer the first question listed above: where is the
            <code><strong>freelist</strong></code>
            stored?
        </p>

        <p>It is best to answer this question using an example, once again with a small memory block, but this
            time also showing the <code><strong>freelist</strong></code> and metadata of the allocated blocks.</p>

        <h4 id="p1.5"><code><strong>freelist</strong></code> storage example</h4>
        <p>Let us assume a total memory block of only 1 KB (i.e., 1024 bytes). At the very beginning, the
            <code><strong>freelist</strong></code> contains a single node representing this entire block. Figure 3 (a)
            below illustrates this situation.
        </p>

        <figure style="text-align: center;">
            <img src="img/freelist1.png" alt="fragmentation-example" style="max-width: auto; height: auto;">
            <figcaption>Figure 3: (a) The initial state of the memory block and <code><strong>freelist</strong></code>.
                (b) After one allocation of 100 bytes (<code><strong>ptr1 = smalloc(100)</strong></code>), the initial
                free block is <code><strong>split</strong></code>
                into an allocated block (along with a header) and a free block with its associated
                <code><strong>freelist</strong></code> node. (Note: the diagram is not drawn to scale).
            </figcaption>
        </figure>

        <p>As shown in the figure, a <code><strong>freelist</strong></code> node is stored in the first 8 bytes (more
            precisely, the first <code><strong>sizeof(common_header_t)</strong></code> bytes) of the free block it
            represents.</p>

        <p>When a block is allocated from, the portion that previously held its <code><strong>freelist</strong></code>
            node
            becomes the newly allocated block’s metadata (shown in Figure 3(b) in blue). This metadata is no longer part
            of the
            <code><strong>freelist</strong></code>. However, it allows the allocator to keep track of the size of the
            allocated block so that it can be correctly returned to the <code><strong>freelist</strong></code> once
            deallocated.
        </p>

        <p>Figures 4 below continues from Figure 3 and illustrate four further steps. Examine the diagrams carefully to
            see the effects of allocation and deallocation on the <code><strong>freelist</strong></code>.</p>

        <figure style="text-align: center;">
            <img src="img/freelist2.png" alt="fragmentation-example" style="max-width: auto; height: auto;">
            <figcaption>Figure 4: (a) Another allocation of 100 bytes.
                (b) Deallocation at ptr1 (the newly freed block is reclaimed into the
                <code><strong>freelist</strong></code>). The brown arrow shows the
                <code><strong>freelist</strong></code> link.(c) Another allocation of 50 bytes (the
                <code><strong>smalloc</strong></code>
                function traverses the <code><strong>freelist</strong></code> and finds space in the first free block.)
                (d) Another allocation of 200 bytes (the <code><strong>smalloc</strong></code> function traverses the
                <code><strong>freelist</strong></code> and finds space in the last free block.)
            </figcaption>
        </figure>

        <p>As should be clear from these examples, the <code><strong>freelist</strong></code> nodes and the metadata
            headers are embedded within the same memory block that is also used for user data storage — we do not use a
            separate memory area dedicated to the <code><strong>freelist</strong></code> or allocation metadata. Also,
            as you may have noticed, when a <code><strong>freelist</strong></code> node is allocated and converted into
            a metadata header, its <code><strong>next</strong></code> pointer field is always set to
            <code><strong>NULL</strong></code>. This leaves 32 bits of storage that could, in principle, be repurposed
            to store other useful information about the allocation — for example, by packing information at the bit
            level. However, in this assignment we will leave it unused.
        </p>


        <p>We are now ready to outline the algorithms for <code><strong>smalloc</strong></code> and
            <code><strong>sfree</strong></code>. For greater clarity, however, let us first examine the initial code
            that reserves a block of memory from the operating system and initializes the
            <code><strong>freelist</strong></code> with a single node representing the entire block as one large free
            region.
        </p>

        <h4 id="p1.6">Initializing memory and the <code><strong>freelist</strong></code></h4>
        <p>Before outlining the pseudocode for the <code><strong>smalloc</strong></code> and
            <code><strong>sfree</strong></code> functions, let us first look at the initial code required to reserve a
            block of memory from the operating system and to initialize the <code><strong>freelist</strong></code> so
            that it contains one node representing the entire block as a single large free region.
        </p>

        <p>We reserve heap space by making an <code><strong>mmap</strong></code> call, as shown below. I have done this
            in a function called <code><strong>get_mem_block</strong></code> which provides a nice and simple interface
            for reuse (if required).</p>

        <div class="code-container" data-filename="c/mmap_c.c">
            <pre><code class="language-c"></code></pre>
        </div>

        <p>In our case, we are not using <code><strong>mmap</strong></code> to map a file into memory. Instead, we use
            it with the <code><strong>MAP_ANONYMOUS</strong></code> flag to reserve a chunk of memory in the process’s
            address space. This reserved memory is private to our process and will be managed internally by our
            allocator, rather than being shared with other processes or tied to any file. For more details on the usage
            and options of <code><strong>mmap</strong></code>, please refer to its man page.</p>

        <p>The following snippet shows the function <code><strong>init_free_list</strong></code>, which initializes the
            <code><strong>freelist</strong></code> to a single-node list representing the entire free memory block. This
            initialization should occur when <code><strong>smalloc</strong></code> is used for the first time, i.e.,
            when the <code><strong>freelist</strong></code> head is <code><strong>NULL</strong></code>. In this case,
            <code><strong>smalloc</strong></code> would first need to call <code><strong>get_mem_block</strong></code>
            to reserve the memory before initializing the freelist.
        </p>


        <div class="code-container" data-filename="c/init_freelist.c">
            <pre><code class="language-c"></code></pre>
        </div>

        <h4 id="p1.7"><code><strong>smalloc</strong></code> and <code><strong>sfree</strong></code> algorithms</h4>

        <p>We now outline the <code><strong>smalloc</strong></code> and <code><strong>sfree</strong></code> algorithms.
            Based on these algorithms, you should also determine which additional helper functions and variables need to
            be added to the <code><strong>freelist</strong></code> implementation to support the operation of both
            functions.</p>


        <p>The pseudocode below has been deliberately kept at a high level, using mostly English, so that you can work
            out the details yourself.</p>

        <p>The <code><strong>smalloc</strong></code> algorithm:</p>
        <pseudocode src="pc/smalloc.pc"></pseudocode>

        <p><strong>Two points to note about the algorithm are as follows:</strong></p>


        <p>
            <strong>Fit type:</strong> In STEP 2, the algorithm finds the first
            <code><strong>freelist</strong></code> node
            with enough space to accommodate the request and allocates from it (a strategy called first-fit). This
            is a good starting
            point; however, other strategies are possible—for example, best-fit (chooses the free node whose size is
            the smallest among those large enough to satisfy the request). We will discuss fit strategies in more
            detail later.
        </p>

        <p>
            <strong>Split:</strong> STEP 3 splits the found free node. This is a key step during allocation. As
            shown in the
            examples, this is where the existing <code><strong>freelist</strong></code> node’s header becomes a
            metadata header, and both headers and block sizes are updated accordingly. Implementing this requires
            pointer arithmetic. When adding or subtracting byte offsets, first cast the pointer from
            <code><strong>void*</strong></code> to <code><strong>char*</strong></code> (or another 1-byte type) to
            ensure byte-wise calculations produce the expected results.
        </p>

        <p>The <code><strong>sfree</strong></code> algorithm:</p>
        <pseudocode src="pc/sfree.pc"></pseudocode>

        <p>As we can see here, the size of the <code><strong>freelist</strong></code> grows with each deallocation. This
            will not always be the case, as we will see in the next sections. For now, however, we should implement this
            basic version and test it.</p>
        </div>

        <div id="p2">
            <h3 id="p2"><small>2. </small>Implement and Test Version 1</h3>
            <p>At this stage, implement the <code><strong>smalloc</strong></code> and
                <code><strong>sfree</strong></code>
                algorithms described above, along with other required code, as
                a working C program.
            </p>

            <p><strong>Some coding tips:</strong></p>

            <p>
                Organize the freelist code into two files:
                <code><strong>freelist.h</strong></code> (declarations: public type definitions, function prototypes,
                and
                macros) and
                <code><strong>freelist.c</strong></code> (function definitions and internal helpers such as insert,
                remove,
                split, etc).
            </p>

            <p>
                Organize the main allocation and deallocation code into two files:
                <code><strong>allocator.h</strong></code> (declarations: the public
                <code>smalloc</code>/<code>sfree</code>
                interface,
                configuration constants, etc.) and
                <code><strong>allocator.c</strong></code> (definitions of <code><strong>smalloc</strong></code>,
                <code><strong>sfree</strong></code>, and other utility functions).
            </p>

            <p>
                The code will be tested in a separate <code><strong>.c</strong></code> test file containing a main
                function.
            </p>

            <p>
                Separate the <code><strong>freelist</strong></code> manipulation functions into the
                <code><strong>freelist</strong></code> files.
                Similarly, allocator-related functions and variables go into the
                <code><strong>allocation</strong></code>
                files. Keep module boundaries clean: <code><strong>freelist.*</strong></code> should expose a clear API;
                <code><strong>allocator.*</strong></code> should use that API.
            </p>

            <h4>Test your implementation</h4>
            <p>The following code is a simple test for the allocator. Read it carefully; your implementation must
                compile
                and run with this test program without any changes to it.</p>

            <p>To do this, in addition to the <code><strong>smalloc</strong></code> and
                <code><strong>sfree</strong></code>
                functions, the allocator module must also provide the following utility functions:
                <code><strong>allocator_list_dump</strong></code> (prints the free list as
                <code><strong>[size]</strong></code> arrows ending with a newline),
                <code><strong>allocator_free_mem_size</strong></code> (returns the total free payload bytes), and
                <code><strong>allocator_req_mem</strong></code> (given a payload size, returns the total bytes required
                including any header). The use and expected output of these functions will be clear from the test
                program
                below and
                the sample output that follows.
            </p>

            <div class="code-container" data-filename="c/basic_allocation_test.c">
                <pre><code class="language-c"></code></pre>
            </div>

            <p>Figure 5 below shows a <strong>sample output</strong> of the program when MEM_SIZE is set to 512 bytes
                (MEM_SIZE is a macro
                constant defined in <code><strong>allocator.h</strong></code>).</p>

            <figure style="text-align: left;">
                <img src="img/basic_test_output.png" alt="basic_test" style="max-width: 80%; height: 100%;">
                <figcaption>Figure 5: An output of the basic test program for <code><strong>MEM_SIZE</strong></code> =
                    1024,
                    <code><strong>N_ALLOCS</strong></code> = 45, <code><strong>MAX_REQ_SIZE</strong></code> = 16
                </figcaption>
            </figure>

            <p>As this output of the basic test shows, an allocation request can fail even when the total free memory is
                sufficient. This
                is due to external fragmentation discussed earlier. In the next section, we will extend the allocation
                and
                deallocation functions and run more detailed tests to observe allocator behavior and explore ways to
                keep
                fragmentation under control (at least until allocation pressure becomes too high).
            </p>
        </div>

        <div id="p3">
            <h3><small>3. </small>Implement and Test Version 2</h3>
            <p>In this part, make two key enhancements to the <code><strong>smalloc</strong></code> and
                <code><strong>sfree</strong></code> implementations.
            </p>
            <p><strong>(1) Add a Different Fit Type to <code>smalloc</code></strong>:</p>
            <p>In STEP 2 of the
                <code><strong>smalloc</strong></code> algorithm, instead of selecting the first free block that can
                satisfy the request (<code><strong>first-fit</strong></code>), choose the <i>smallest block that can
                    satisfy the request</i> (<code><strong>best-fit</strong></code>).
            </p>
            <p>Run the small test program (with <code><strong>MEM_SIZE</strong></code> = 1024,
                <code><strong>N_ALLOCS</strong></code> = 45, <code><strong>MAX_REQ_SIZE</strong></code> = 16) and
                observe
                any performance differences when using
                <code><strong>best-fit</strong></code>.
            </p>
            <p>Overall, <code><strong>best-fit</strong></code> tries to
                preserve larger blocks but may also leave many
                small remainders. As a trade-off, <code><strong>smalloc</strong></code> often must scan most or all of
                the <code><strong>freelist</strong></code>, so it can be slower than
                <code><strong>first-fit</strong></code> (Note: In this basic test program, there may not be a noticeable
                difference between the two fits. We will use a more elaborate stress test later.).
            </p>

            <p><strong>(2) Merge Consecutive Free Blocks in <code><strong>sfree</strong></code></strong>:</p>
            <p>Currently, in STEP 3 of <code><strong>sfree</strong></code> we add the newly freed block at the start of
                the list. This can create fragmentation that is sometimes avoidable—especially when neighboring free
                blocks could be merged into a single larger block. Implement a <code><strong>merge</strong></code>
                function in the allocator module (add any small helper functions in the
                <code><strong>freelist</strong></code> module as needed) and call <code><strong>merge</strong></code> in
                STEP 3 of <code><strong>sfree</strong></code>.
            </p>
            <p>For <code><strong>merge</strong></code> to work well, don’t insert the freed block only at the head.
                Instead, insert it in address order; keep the <code><strong>freelist</strong></code> sorted by block
                address. This lets <code><strong>merge</strong></code> combine adjacent blocks into one larger block.
            </p>
            <p>Run the small test program (with <code><strong>MEM_SIZE</strong></code> = 1024,
                <code><strong>N_ALLOCS</strong></code> = 45, <code><strong>MAX_REQ_SIZE</strong></code> = 16) and
                observe
                the difference.
            </p>
        </div>

        <div id="p4">
            <h3><small>4. </small> Stress-test Version 2</h3>
            <p>The test program we have used so far works on a small memory, performs a few allocations, and only prints
                a few stats.</p>
            <p>To better assess the performance of the enhancements in Version 2, now perform a stress-test of
                <code><strong>smalloc</strong></code> and <code><strong>sfree</strong></code>.
            </p>

            <p>Download the test program here: <code><strong><a href="c/allocation_stress_test.c"
                        download="c/allocation_stress_test.c">allocation_stress_test.c</a></strong></code></p>

            <p>Please read the READ ME block at the top of the code. To make this program work, you'd need to add
                another helper function to the allocator module (with appropriate additions to the
                <code><strong>freelist</strong></code> module). Please read the comments in
                <code><strong>allocation_stress_test.c</strong></code> for details.
            </p>

            <p>Figure 6 below shows a sample output from the stress-test.</p>

            <figure style="text-align: left;">
                <img src="img/stress_test_output.png" alt="basic_test" style="max-width: 50%; height: auto;">
                <figcaption>Figure 6: An output of the stress-test program for <code><strong>MEM_SIZE</strong></code> =
                    10 * 1024 * 1024 (10 MB), and other parameters as specified in
                    <code><strong>allocation_stress_test.c</strong></code>.
                </figcaption>
            </figure>

            <p>The run in Figure 6 was done using <code><strong>best-fit</strong></code> without
                <code><strong>insert-in-order / merge </strong></code>.
            </p>
            <p>The table below briefly summarizes the metrics of the stress-test along with the outputs from the run in
                Figure 6:</p>

            <table border="1" align="center">
                <thead>
                    <tr>
                        <th>Metric</th>
                        <th>Meaning</th>
                        <th>The run in Figure 6</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Total Memory</td>
                        <td>Heap size</td>
                        <td>10.00 MB</td>
                    </tr>
                    <tr>
                        <td>Requests</td>
                        <td>Allocation attempts made</td>
                        <td>50,000</td>
                    </tr>
                    <tr>
                        <td>Memory Requested</td>
                        <td>Sum of all requested bytes</td>
                        <td>756.29 MB</td>
                    </tr>
                    <tr>
                        <td>Memory Allocated</td>
                        <td>Sum of bytes actually allocated</td>
                        <td>80.82 MB</td>
                    </tr>
                    <tr>
                        <td>Successful Allocations</td>
                        <td>Number of successful <code><strong>smalloc</strong></code> calls</td>
                        <td>11,311</td>
                    </tr>
                    <tr>
                        <td>Successful Requests (%)</td>
                        <td><span>\(\text{Successful Allocations} / \text{Requests}\)</span></td>
                        <td>22.62%</td>
                    </tr>
                    <tr>
                        <td>Successful Allocation (bytes)</td>
                        <td>Share of requested bytes that were allocated</td>
                        <td>10.69%</td>
                    </tr>
                    <tr>
                        <td>Requests (to first failure)</td>
                        <td>Count before the first failure</td>
                        <td>1,549</td>
                    </tr>
                    <tr>
                        <td>Memory Allocated (to first failure)</td>
                        <td>Bytes allocated before first failure</td>
                        <td>23.05 MB</td>
                    </tr>
                    <tr>
                        <td>Free Memory at Failure</td>
                        <td>Free bytes when failure happened</td>
                        <td>2.32 MB (2,377.28 KB)</td>
                    </tr>
                    <tr>
                        <td>Request Size at Failure</td>
                        <td>Size of the failing request</td>
                        <td>31.00 KB</td>
                    </tr>
                    <tr>
                        <td>Memory Utilization at Failure</td>
                        <td>Fraction of heap in use at failure</td>
                        <td>0.77</td>
                    </tr>
                    <tr>
                        <td>Bytes-to-Failure Turnover (BTF)</td>
                        <td>Heaps-worth of memory allocated before failure</td>
                        <td><span>\(2.31 \times \mathrm{MEM\_SIZE}\)</span></td>
                    </tr>
                    <tr>
                        <td>Freelist Length (Final)</td>
                        <td>Free blocks at end</td>
                        <td>10,831</td>
                    </tr>
                    <tr>
                        <td>Freelist Length (Max)</td>
                        <td>Peak free blocks during run</td>
                        <td>10,831</td>
                    </tr>
                    <tr>
                        <td>External Fragmentation (Final)</td>
                        <td><span>\(1 - \frac{L}{F}\)</span> (L = largest free block, F = total free bytes)
                        </td>
                        <td>0.9998</td>
                    </tr>
                    <tr>
                        <td>External Fragmentation (Max)</td>
                        <td>Peak <span>\(1 - \frac{L}{F}\)</span> during run</td>
                        <td>0.9998</td>
                    </tr>
                </tbody>
            </table>

            <h4>Stress-test fit-types and merge performance</h4>
            <p>Use the stress test for the following cases and make observations:</p>
            <p><strong>Case 1:</strong> first-fit / no merge</p>
            <p><strong>Case 2:</strong> best-fit / no merge (in this, notice the BTF difference from first-fit).</p>
            <p><strong>Case 3:</strong> best-fit or first-fit / merge enabled (in this case notice the fragmentation
                marker difference from the cases without merge.)</p>
            <p><strong>Case 4:</strong> find the tipping point, i.e., stress level where merge enabled allocation also
                fails.
        </div>

        <div id="p5">
            <h3><small>5. </small> Proposed Extension: Size-Class Arenas</h3>
            <p>When I run a <code><strong>$ vmmap -summary &lt;PID&gt;</strong></code> on my Mac terminal using a
                browser tab's PID, I see a large memory map, a small part of which is shown in Figure 7 below.</p>

            <figure style="text-align: left;">
                <img src="img/vmmap_mac.png" alt="basic_test" style="max-width: 90%; height: auto;">
                <figcaption>Figure 7: A tiny part of the <code><strong>$ vmmap -summary &lt;PID&gt;</strong></code>
                    output.
                </figcaption>
            </figure>

            <p>This shows that the process’s heap is split into size-based zones (Tiny, Small, Medium). Each zone is its
                own chunk of memory, and the map lists how much memory each zone has and how much is in use. In short:
                allocations are grouped by size and managed separately.</p>

            <p>The intuition is simple: when chunk sizes vary a lot, freeing them leaves many small gaps, so big
                requests can’t find one big gap. Grouping allocations by size reduces this variability and helps
                lower external fragmentation.</p>

            <p>In this part, extend your <code><strong>smalloc</strong></code> and <code><strong>sfree</strong></code>
                implementation to manage three <code><strong>mmap</strong></code>-backed arenas—one each for tiny,
                small, and medium requests—each with its own <code><strong>freelist</strong></code>. Route requests by
                their required size, while maintaining the <code><strong>best-fit</strong></code> and
                <code><strong>merge</strong></code> features.
            </p>

            <h4>The updated algorithms</h4>

            <p>Following are the algorithms augmented to include the size-class arena feature.</p>

            <p>The updated <code><strong>smalloc</strong></code> algorithm:</p>
            <pseudocode src="pc/smalloc_sca.pc"></pseudocode>

            <p>The updated <code><strong>sfree</strong></code> algorithm:</p>
            <pseudocode src="pc/sfree_sca.pc"></pseudocode>

            <h4>Zone sizes and size boundaries</h4>
            <p>For consistency, we keep the total memory size to 10 MB, setting the zone sizes to 1 MB (TINY), 3 MB
                (SMALL), and 6 MB (MEDIUM).</p>
            <p>In the current settings of the stress test we make request sizes in the range [1 byte – 32 KB]. A useful
                size bracket to zone mapping could be (sizes include the header size):</p>
            <ul>
                <li><code><strong>TINY</strong></code>: up to 256 bytes</li>
                <li><code><strong>SMALL</strong></code>: 257 bytes to 8 KB</li>
                <li><code><strong>MEDIUM</strong></code>: > 8 KB up to 32 KB</li>
            </ul>

            <h4>Stress-test your implementation</h4>
            <p>Implement the three-zone (TINY/SMALL/MEDIUM) version, then run the stress test and note: (i) successful
                requests / total requests, (ii) requests and bytes up to the first failure, (iii) free memory, request
                size, and utilization at first failure, (iv) bytes-to-failure turnover, and (v) freelist length (final
                and max).</p>
            <p>For fragmentation, print external fragmentation \((1 - L/F)\) for each zone (TINY, SMALL,
                MEDIUM) and also an overall value using combined \(L\) and \(F\) across all zones. Compare these results
                with your single-heap version and note your observations.</p>
        </div>

        <div id="p6">
            <h3><small>6. </small>Further Enhancements</h3>
            <p>The following are optional suggestions for future work. You are not expected to attempt them in this
                assignment.</p>

            <p>These ideas are based on real-world techniques used in modern memory allocators and can be helpful
                learning extensions if you’d like to go further.</p>

            <p>One direction is to explore allocators that use fixed-size memory chunks—often called pages or slabs.
                These are used in systems like the Linux kernel’s slab allocator and in <a
                    href="https://github.com/jemalloc/jemalloc"
                    target="_blank"><code><strong>jemalloc</strong></code></a>. The
                idea is to break memory into equal-sized blocks and reuse them efficiently, which helps reduce
                fragmentation and improve speed.</p>

            <p>Another direction is to learn how memory allocation works in multithreaded programs. Allocators like <a
                    href="https://microsoft.github.io/mimalloc/"
                    target="_blank"><code><strong>mimalloc</strong></code></a> and <a
                    href=href="https://github.com/jemalloc/jemalloc/"
                    target="_blank"><code><strong>jemalloc</strong></code></a> support
                multiple arenas to reduce locking, so many threads can allocate memory at the same time. This improves
                performance on multicore systems and helps avoid bottlenecks.</p>

            <p>A third direction is to explore how some allocators are designed to help with debugging and memory
                safety. They can detect issues like memory leaks, double frees, or use-after-free bugs. These features
                are valuable in real applications and give insight into how debugging tools work.</p>

            <p>Each of these directions connects to how real software systems manage memory. They are great practice
                areas if you want to understand allocators better or build one yourself.</p>
        </div>

        <hr>
        <p style="text-align: center; font-style: color: #555; margin-top: 2em;">
            — End of Statement —
        </p>

    </section>
    </div>
</body>

</html>
